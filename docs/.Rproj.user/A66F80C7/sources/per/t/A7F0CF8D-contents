---
output:
  pdf_document: default
  html_document: default
---
# Water Quality Statistics  

```{r knitrinitmcmc1, echo=FALSE,  message=FALSE, warning=FALSE, cache=FALSE}
library(knitr)
library(rmdformats)
library(hrbrthemes)
library(tidyverse)
library(showtext)
library(kableExtra)
library(MCMCglmm)
font_add("Roboto Condensed","robotocondensed-regular.ttf")


### Global options

options(warning = FALSE,message = FALSE,echo=FALSE)
opts_chunk$set(echo=FALSE,
               message=FALSE,
                warning=FALSE)
opts_knit$set(warning = FALSE,message = FALSE,echo=FALSE)

## ggploting theme
#theme_set(hrbrthemes::theme_ipsum_rc())
#hrbrthemes::import_roboto_condensed()
#hrbrthemes::update_geom_font_defaults()
```
We developed a spatial regression model to estimate concentrations for constituents of concern (COCs) in Puget Sound urban stormwater. We first used a linear mixed model to select spatial regression parameters. We then used a censored Markov chain Monte Carlo simulation to perform final regressions. 

## Data Sources 


```{r knitr_init, cache=FALSE, include=FALSE}
#rm(list = ls())
#set the working directory 
#setwd("~/repos/stormwaterheatmap/R-scripts/WatershedRegression")

#load packages
library(knitr)
library(tidyverse)
library(car)
library(caret)
library(psych)
library(DataExplorer)
library(dplyr)
library(readr)
library(lme4)
library(nlme)
library(hrbrthemes)
library(sjPlot)
library(Metrics)



## Global options

opts_chunk$set(prompt=FALSE,
               message=FALSE,
               warning=FALSE)
options(scipen = 1, digits = 3)

#set seed for reproducibility 
set.seed(50)
```



### Outfall Data

The primary source of measured stormwater data is the S8.D Municipal Stormwater Permit Outfall Data (referred to as the S8 Data in this document) provided by the Washington Department of Ecology [@No2015]. Special Condition S8.D of the 2007-2012 Phase I Municipal Stormwater Permit required permittees to collect and analyze data to evaluate pollutant loadings of stormwater discharged from different land uses: high density (HD) residential, low density (LD) residential, commercial, and industrial. Phase I Permittees^[Cities of Tacoma and Seattle; King, Snohomish, Pierce and Clark counties; Ports of Tacoma and Seattle] collected water quality and flow data, sediment data, and toxicity information from stormwater discharges during storm events.

The stormwater outfall data is available from Ecology via a open-data api at: https://data.wa.gov/Natural-Resources-Environment/Municipal-Stormwater-Permit-Outfall-Data/d958-q2ci.



```{r echo=FALSE, message=FALSE, warning=FALSE}
all.S8.data <- read.csv("data/S8_data.csv",
                        stringsAsFactors = FALSE )

#filter out rejected data
all.S8.data <- (filter(all.S8.data,!result_data_qualifier %in% 'REJ'))

#filter out replicates 
all.S8.data <- (filter(all.S8.data,!sample_replicate_flag %in% 'Y'))

#change nondetect warnings to detects
warnings <- all.S8.data$nondetect_flag == "WARNING"
all.S8.data$nondetect_flag[warnings] <- FALSE 

#Change NA to detect
all.S8.data$nondetect_flag[is.na(all.S8.data$nondetect_flag)] <- FALSE

#Change season to factor 
all.S8.data$season <- as.factor(all.S8.data$season)


```

COCs analyzed in this study are show in Table \@ref(tab:SelectParameters). 

```{r SelectParameters}
#Select Parameters
params <- c('Zinc - Water - Total',
 'Copper - Water - Total',
 'Nitrite-Nitrate - Water - Dissolved',
 'Lead - Water - Total',
 'Total Phosphorus - Water - Total',
 'Total Suspended Solids - Water - Total',
 'Total Phthalate - Water - Total',
'Total PAH - Water - Total',
#'Chrysene - Water - Total',
'CPAH - Water - Total',
'HPAH - Water - Total' 
#'Total Kjeldahl Nitrogen - Water - Total',
#'Total PCB - Water - Total'
)

#save a list of all the parameters in case we want to use mor. 
params.all <- data.frame(unique(all.S8.data$parameter))
s8data <- all.S8.data 
kable(params,col.names = "Constituents of concern")
#
```

We extracted data for these COCs, and performed minimal data cleaning. We filtered out rejected data (values with a `R` or `REJ` flag), removed replicates, and removed three data points that were obvious outliers. While our analysis is not overly sensitive to outliers, three parameters had reported data that were orders of magnitude higher than the rest of the data. One high-outlier value was removed for each of the following COCs: Total Suspended Solids, Nitrite-Nitrate, and Total Phosphorus.  

Outliers were removed for Figure  \@ref(fig:outlier1) shows data before outliers were removed. Figure  \@ref(fig:outlier2) shows data after outliers were removed. 


```{r dataClean,  message=FALSE, warning=FALSE, include=FALSE}
s8data <- all.S8.data %>% 

  dplyr::select(
    study_name,
    location_id,parameter,
    type,
    season,
    new_result_value,
    nondetect_flag,
    study_id,
    access_id,
    field_collection_end_date,
    field_collection_start_date,
    type)


#rename some columns
colnames(s8data)[colnames(s8data) == "location_id"] <- "Location"
colnames(s8data)[colnames(s8data) == "new_result_value"] <-
  "concentration"
s8data$nondetect_flag <- as.logical(s8data$nondetect_flag)
s8data$concentration <- as.numeric(s8data$concentration)


```




  
```{r outlier1, fig.height=8}
#make a function for scatter plots 
scatter_cocs <- function(df.coc,title) {
 p <- ggplot(df.coc, aes(1, concentration)) + geom_jitter() + labs(
  title = title,
  subtitle = "Data collected 2009-2013",
  caption =
    " Data source: Ecology, 2015",
  x = "Observations"
)
p + facet_wrap( ~ parameter, scales = 'free')+theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) 
}

scatter_cocs(s8data[which(s8data$parameter %in% params),],'All Observations')
```
   

```{r outlier2, fig.height=8}
#remove and replot 

outlierParams <- c("Total Suspended Solids - Water - Total", "Total Phosphorus - Water - Total", "Nitrite-Nitrate - Water - Dissolved")

#This removes the highest values 
outlierVals <-
  top_n(group_by(s8data[which(s8data$parameter %in% outlierParams), ], parameter), 1, concentration)$concentration

s8data <- s8data %>%
  group_by(parameter) %>%
  slice(which(!(
    parameter %in% outlierParams & concentration %in% outlierVals
  )))

scatter_cocs(s8data[which(s8data$parameter %in% params),],'All Observations - Outliers Removed')

```


## Spatial data 

### Land use 

For this study, we did not rely on the permittee's self-reported land use type. In order to employ a consistent analysis across different monitored watersheds we extracted land use  was extracted from Ecology’s 2010 Statewide Land use data set^[See: https://fortress.wa.gov/ecy/gispublic/DataDownload/ECY_CAD_Landuse2010.htm for more information]. Ecology generated the coverage from digital county tax parcel layers using Department of Revenue (DOR) two digit land use codes (see; WAC 458-53-030, Stratification of assessment rolls - real property).

### Landscape data sets 

For each watershed contained in the S8 dataset, potentially relevant data was extracted from various sources. These are shown below:

| Layer                   | ID          | Source |
|-------------------------|-------------|---------| 
|   Nighttime Lights      |  nighttime_lights
  |       [Global Radiance Calibrated Nighttime Lights](https://doi.org/10.1117/12.2023107)    
|  Particulate Matter 2.5μm |  pm25      |   [van Donkelaar et al. 2018.](https://doi.org/10.7927/H4ZK5DQS)   
|    Rooftop Density      |    roofs   |     [Microsoft AI US Building Footprints](https://github.com/microsoft/USBuildingFootprints)   |     1  |
| Imperviousness          | impervious      | TNC Puget Sound land cover
|Age of Impervious Surface|change_year_index |[Tsinghua University FROM-GLC year of change to impervious surface](http://doi.org/10.1016/j.rse.2019.111510)
|Logarithm of Population Density |logPopulation |[CIESIN - Columbia University Gridded Population of the World, Version 4](https://doi.org/10.7927/H49C6VHW)
)
|Logarithm of Average Daily Traffic Volume  |logTraffic|[INRIX Traffic](https://inrix.com/products/volume)

## Methods

### Pre-processing of spatial data 
In order to use the landscape data at an appropriate scale across the study area, spatial predictors were stacked and then convolved with a 100-meter gaussian kernel. This resulted in a "fuzzy" set of predictors that could apply across dataset boundaries. These values were then extracted for each monitored watershed. Values and scaled and centered for regression purposes. 

```{r}
#Spatial predcitors have been extracted and saved as a csv file. 
#spatial_data<-read_csv("data/spatialPredictors_4_13.csv", col_types = cols(X1 = col_skip()))
spatial_data <- read_csv("data/spatialPredictors_5_14.csv")
#RES and COM are compositional data. Change to a ratio
spatial_data$LU_ratio = spatial_data$COM/spatial_data$RES 
spatial_data <- dplyr::select(spatial_data, -c(RES,COM,.geo))
#merge spatial predictors with monitoring data 
s8data.wPredictors <<- merge(s8data, spatial_data)%>% 
  dplyr::select(-c(depSplusN))

```




```{r functions}
getBaseFormula <- function(df.coc) {
  #Function to make a formula for prediction
  predictors <- df.coc %>%
    select_if(is.numeric) %>%
    dplyr::select(-c(concentration, access_id)) %>%
    colnames()
  return(as.formula(paste(
    "(concentration) ~",  (paste((predictors),  collapse = " + ")), " + (1|Location)"
  )))
  
}
```

 
```{r}
plot_s8 <- function(coc) {
    df.coc <- (base::subset(s8data.wPredictors,
                parameter == coc))
  #plot the data to inspect 
  plot <- ggplot(data=(df.coc))+geom_point(aes(x=Location,y=concentration))+scale_y_log10()+labs(
      y = "Concentration (µg/L)",
      x = "Location",
      title =  "Measured Concentrations",
      subtitle = coc ) 
  return(plot)
}
```



<!-- {r} -->
<!-- # #Calculate variance-inflation factors.  -->
<!-- #  -->
<!-- # calc_vif_base <- function(coc) { -->
<!-- #   df.coc <- (base::subset(s8data.wPredictors, -->
<!-- #                 parameter == coc)) -->
<!-- #   base_formula <- getBaseFormula(df.coc)#returns a formula with all predictors -->
<!-- #   model.1 <<- lmer(base_formula, data = df.coc, na.action = na.omit) -->
<!-- #   v <- sort(vif(model.1),decreasing=TRUE) -->
<!-- #   return(v) -->
<!-- #   #kable(v,caption="Variance Inflation Factors - not filtered") #display the vif of the dataset -->
<!-- # } -->

<!-- ``` -->


<!-- ## Function to iteratively remove mulitcolinear predictors  -->
<!-- Same as above, expect multicolinear predictors are removed.  -->
```{r}
## *Check VIF
 
check_vif <- function(coc) {
  df.coc <- (base::subset(s8data.wPredictors,
                parameter == coc))
  base_formula <- getBaseFormula(df.coc)#returns a formula with all predictors
  model.1 <- lmer(base_formula, data = df.coc, na.action = na.omit) #make into a lmer object 
  v <- sort(vif(model.1),decreasing=TRUE)
  
  #if the VIF of the highest ranked predictor is >10 then iteratively remove
  model_object <- model.1 #start with model object as the base model (all predictors included)
  
  
  for (i in 1:20) {
    interim_v <- sort(vif(model_object), decreasing = TRUE)
    if (max(interim_v) < 10) {
      break
    }
    predictor_to_drop = as.name(names(interim_v)[which(interim_v == max(interim_v))])
    model_object <-
      stats::update(model_object, paste(".~ . -", predictor_to_drop))
    }
  
  m1Terms <- (labels(terms(model.1)))
  m2Terms <- labels(terms(model_object))
  
  #compare the terms to get a list of the dropped terms
  droppedTerms <- setdiff(m1Terms, m2Terms)
  
  #make a list of selected predictors
  predictors <- m2Terms#colnames(model.frame(model_object)) 

  
  #filter df.coc to remove dropped terms.
  df.coc = dplyr::select(df.coc, -(droppedTerms))
  return(list("vif" = interim_v,"dropped" = droppedTerms,"predictors" = predictors))
  #kable(droppedTerms,caption = "These terms were dropped")
  
  #kable(interim_v,caption="Variance Inflation Factors - multicolinear factors dropped")
}

```

<!-- ## Function to perform stepwise selection and return a series of best models  -->

```{r stepwise, cache=TRUE}
## Stepwise Selection

#forward_selection(TRUE,coc,model_info$predictors)

# Extract the model that step found:

#perform forward selection on model parameters. First for non-transformed data, then for log-transformed data
forward_selection <- function(seasonal.bin, coc,predictors) {
  #seasonal.bin = binary (T/F) if seasonal model should be used
  library(lmerTest)
  #make this a lmer object 
  df.coc <- (base::subset(s8data.wPredictors,
                parameter == coc)) 
  model_object_formula <- as.formula(paste(
    "concentration ~",  (paste((predictors),  collapse = " + ")), " + (1|Location)"))
  
  model_object <- lmer(model_object_formula,data=df.coc)
  
  step.2 <-  lmerTest::step(model_object,reduce.random=FALSE,data=df.coc)
  step.2.log <- lmerTest::step(stats::update(model_object, log(concentration)~.))
  
  #extract the models 
  model.3 <- get_model(step.2)
  model.3.log <- get_model(step.2.log)
  
  #perform forward selection on model parameters, this time add seasonality . First for non-transformed data, then for log-transformed data
  step.4 <- lmerTest::step(stats::update(model_object,.~.+season))
  step.4.log <- lmerTest::step(stats::update(model_object,log(concentration) ~.+season))
  model.4 <- get_model(step.4)
  model.4.log <- get_model(step.4.log)
  
  #get formulas 
  model.3.formula <- as.formula(model.3@call$formula)
  model.3.log.formula <- as.formula(model.3.log@call$formula)
  model.4.formula <- as.formula(model.4@call$formula)
  model.4.log.formula <- as.formula(model.4.log@call$formula)
  
  #detach lmer test and remove the models. Keep the formulas. 
  detach("package:lmerTest", unload=TRUE)
  rm(model.3,model.3.log,model.4,model.4.log)
  
  #use lmer for performing modeling
  #calculate base model 
  df.coc <- (base::subset(s8data.wPredictors,
                parameter == coc)) 
  model.base <- lmer(model_object_formula,data=df.coc)
  model <- lmer(model.3.formula,data=df.coc)
  log_model<-  lmer(model.3.log.formula,data=df.coc)
  
  if(seasonal.bin) {
      #if seasonal model switch is on, calc seasonal models
    model_with_seasonality <- lmer(model.4.formula,data=df.coc)
    model_with_seasonality_log <- lmer(model.4.log.formula,data=df.coc)
      #add to list 
    modelList <- c(model,log_model,model_with_seasonality,model_with_seasonality_log)
    
    }
    else {
    modelList <-c(model,log_model)
    modelLables <-c('linear','log-linear') 
    }
   

 
 return(modelList)#,show.aic = TRUE)# = FALSE, title=coc, dv.labels = modelLables) 
  # #make a table of coefficients 
  # tab_model(modelList,
  #   model_log,
  #   model_with_seasonality,
  #   model.with_seasonality_log,
  #   show.aic = TRUE,auto.label = FALSE, title=coc, dv.labels = c('linear','log-linear','linear seasonal','log-linear seasonal'))#file=paste0("results/",coc,".html"))
}
```



```{r}

results = c()
plots = c()
vifs = c()
tabs = c()

for (i in 1:length(params)){
coc = params[i]
df.coc <- (base::subset(s8data.wPredictors,
                parameter == coc)) 
plots[[coc]] <- plot_s8(coc)
model_info <- check_vif(coc)
vifs[[coc]] <- model_info$vif

results[[coc]] = forward_selection(TRUE,coc,model_info$predictors)}
modelLabels <-c('linear','log-linear','linear seasonal','log-linear seasonal') 

```


```{r}
#Wrapper function for displaying results for individual cocs. 

show_resultsFun <- function(j){
#get parameter label 
lab = params[j]
models <- results[[j]]
  #print((summary(models[[k]])))
  #plot(models[[k]],,main=paste(lab,"\n","Resididuals"))
 (qqmath(models[[2]],main=paste(lab,"\n",modelLabels[2],"\n","QQ plot of resididuals")))
}

```



### Controlling for multicolinearity 

To address multicolinearity, we calculate the variance inflation factor (VIF) and iteratively remove paramters with the highest VIF. We keep removing parameters one at a time until all VIF values are below 10.0. Table 
```{r vifTable, echo=FALSE, message=FALSE, warning=FALSE}
j=1
  lab=params[j]
  kable(vifs[j],
      caption = paste("Variance inflation factors",lab),col.names = c("vif"))
j=2
  lab=params[j]
  kable(vifs[j],
      caption = paste("Variance inflation factors",lab),col.names = c("vif"))
j=3
  lab=params[j]
  kable(vifs[j],
      caption = paste("Variance inflation factors",lab),col.names = c("vif"))
j=4
  lab=params[j]
  kable(vifs[j],
      caption = paste("Variance inflation factors",lab),col.names = c("vif"))
j=5
  lab=params[j]
  kable(vifs[j],
      caption = paste("Variance inflation factors",lab),col.names = c("vif"))
j=6
  lab=params[j]
  kable(vifs[j],
      caption = paste("Variance inflation factors",lab),col.names = c("vif"))
j=7
  lab=params[j]
  kable(vifs[j],
      caption = paste("Variance inflation factors",lab),col.names = c("vif"))
j=8
  lab=params[j]
  kable(vifs[j],
      caption = paste("Variance inflation factors",lab),col.names = c("vif"))
j=9
  
lab=params[j]
  kable(vifs[j],
      caption = paste("Variance inflation factors",lab),col.names = c("vif"))
  
j=10
  lab=params[j]
  kable(vifs[j],
      caption = paste("Variance inflation factors",lab),col.names = c("vif"))
```

### Model Selection 
Four potential models were evaluated for each COC: 
1. **linear** - Non-transformed concentrations with location random effects
2. **log-linear** - Log-transformed concentrations with location random effects
3. **linear seasonal** - Non-transformed concentrations with location random effects with the addition of a seasonal fixed-effect
4. **log-linear seasonal** - Log-transformed concentrations with location random effects with the addition of a seasonal fixed-effect

Seasonal factors were included in the model selection by designating an integer corresponding to the season in which data were collected (1=Winter, 2=Spring, 3=Summer, 4 = Autumn)

Model selection was performed through Backward elimination of random-effect terms followed by backward elimination of fixed-effect terms. Denominator degrees of freedom and F-statistics were calculated using Satterthwaite's method. 

Most COC concentrations appeared to have a log-linear distribution as shown in the plots below. 

```{r qqplots, echo=FALSE}

par(mfrow=c(2,5))
show_resultsFun(1)
show_resultsFun(2)
show_resultsFun(3)
show_resultsFun(4)
show_resultsFun(5)
show_resultsFun(6)
show_resultsFun(7)
show_resultsFun(8)
show_resultsFun(9)
show_resultsFun(10)
```

####  Model Selection Results  

```{r}
j=1
models <- results[[j]]
summary(models[[1]])
for (k in 2:2){
  print((summary(models[[k]])))
  #plot(models[[k]],,main=paste(lab,"\n","Resididuals"))
 
}
```


```{r}

tableSummary <- function(z){
coc = params[z]
tab_model(results[coc][[1]],   show.aic = TRUE,auto.label = FALSE, title=coc, dv.labels = c('linear','log-linear','linear seasonal','log-linear seasonal'))
}

tableSummaryNoSeason <- function(z){
coc = params[z]
tab_model(c(results[coc][[1]][1],results[coc][[1]][2]),   show.aic = TRUE,auto.label = FALSE, title=paste0(coc, " - No seasonal efects"), dv.labels = c('linear','log-linear'))
}

tableSummaryYesSeason <- function(z){
coc = params[z]
tab_model(c(results[coc][[1]][3],results[coc][[1]][4]),   show.aic = TRUE,auto.label = FALSE, title=paste0(coc, " - With seasonal efects"), dv.labels = c('linear seasonal','log-linear seasonal'))
}

```



Linear model results for each COC are shown in the following tables. In general, the model with the lowest AIC was selected to move on to the Bayesian analysis. Only predictors that are statistically significant are shown. In some cases, no predictors were significant. In those cases, only the model intercept is reported. 

##### Zinc

**Model with lowest AIC:** `log-linear`    
**Predictors Selected:**    `change_year_index`

```{r Zn, fig.cap="Zinc Table"}
z=1
tableSummaryNoSeason(z)
tableSummaryYesSeason(z)
```

##### Copper

**Model with lowest AIC:** `log-linear`    
**Predictors Selected:**    `roadDensity`
```{r}
z=2
tableSummaryNoSeason(z)
tableSummaryYesSeason(z)

```
### Nitrite-Nitrate

**Model with lowest AIC:** `log-linear` *(seasonal effects not significant)*    
**Predictors Selected:**    none
```{r}
z=3
tableSummaryNoSeason(z)
```
##### Lead

**Model with lowest AIC:** `log-linear` *(seasonal effects not significant)*    
**Predictors Selected:**   `logPopulation`, `roadDensity`
```{r}
z=4
tableSummaryNoSeason(z)
tableSummaryYesSeason(z)

```

##### Total Phosphorus 

**Model with lowest AIC:** `log-linear seasonal`    
**Predictors Selected:**   `roadDensity`
```{r}
z=5
tableSummaryNoSeason(z)
tableSummaryYesSeason(z)

```
##### Total Suspended Solids

**Model with lowest AIC:** `log-linear`    
**Predictors Selected:**   `roadDensity`
```{r}
z=6
tableSummaryNoSeason(z)
tableSummaryYesSeason(z)

```


##### Total Phthalate
**Model with lowest AIC:** `log-linear`    
**Predictors Selected:**   none
```{r}
z=7
tableSummaryNoSeason(z)
tableSummaryYesSeason(z)

```

### Total PAH
**Model with lowest AIC:** `log-linear`    
**Predictors Selected:**   none
```{r}
z=8
tableSummaryNoSeason(z)


```


##### Total CPAH 
**Model with lowest AIC:** `linear` 
**Predictors Selected:**   `logPopulation`, `roadDensity`
```{r}
z=9
tableSummaryNoSeason(z)
tableSummaryYesSeason(z)

```

##### Total HPAH 
**Model with lowest AIC:** `linear` *(seasonal effects not significant)*  
**Predictors Selected:**   `logPopulation`, `roadDensity`
```{r}
z=10
tableSummaryNoSeason(z)

```




```{r}
# Perform MCMC modeling 
## Functions 
#Some helper functions to help 

##### Function to add a survival object to the S8 dataframe 
add_surv <- function(df) {
  df$cenMin <- ifelse(df$nondetect_flag,-Inf, (df$concentration))
  df$cenMax  <- (df$concentration)
  df$cenMin_log <- ifelse(df$nondetect_flag,-Inf, log(df$concentration))
  df$cenMax_log  <- log(df$concentration)
  
  return(df)
}
```

```{r}
##### Function to return a chart of predictions from the model 
scatter_predict <- function(model_df,predictions) {
# model_to_predict <- CuModel 
# coc = params[2]
# df <- (subset(s8data.wPredictors, parameter == coc)) %>%
#   add_surv()
# predictions <- predict(model_to_predict, newdata=df, 
#          type="response", interval="none", level=0.95, it=NULL, 
#          posterior="all", verbose=FALSE, approx="numerical")
# 
 obs <- log(model_df$concentration)
 
 ggstatsplot::ggscatterstats(
  data =tibble(p = predictions, obs = obs,L = model_df$Location),
  x = p,
  y = obs,
  type = "bf",
  point.width.jitter = 0.02,
  #point.height.jitter = 0.1,
  marginal = FALSE,
  xlab = "Predicted log(µg/L)",
  ylab = "Observed  log(µg/L)",
  title = coc,
  results.subtitle = FALSE,
  subtitle = "Predictions vs. Observations",
  smooth.line.args = list(size = 1, color = "blue"),
  messages = FALSE
)
}

```

```{r}
##### add tidy and glance functions to the mcmcglmm objects since they don't play nicely with tidyverse objects. 

# add custom functions to extract estimates (tidy) and goodness-of-fit (glance) information
tidy.MCMCglmm <- function(object, ...) {
    s <- summary(object, ...)
    ret <- tibble::tibble(term = row.names(s$solutions),
                          estimate = s$solutions[, 1],
                          conf.low = s$solutions[, 2],
                          conf.high = s$solutions[, 3])
    ret
}
glance.MCMCglmm <- function(object, ...) {
    ret <- tibble::tibble(dic = object$DIC,
                          n = nrow(object$X))
    ret
}

# estimate a simple model
#model <- MCMCglmm(PO ~ 1 + plate, random = ~ FSfamily, data = PlodiaPO, verbose=FALSE, pr=TRUE)
```

## mcmc_calc function  

This is the main funciton to run the mcmc model. It does the following:   
1. subsets a dataframe to include only the parameter we want to predict  
2. adds a survival object to handle censored data  
3. sets up a simiple prior structure  
4. performs mcmc modeling on either the log-transformed or non-log transformed responses.   
5. returns the results   

```{r}
mcmc_calc <- function(coc.local, fixed_list, lhs) {
  
  df <- (subset(s8data.wPredictors, parameter == coc.local))

   data <-
  df %>%
  add_surv()
#make the prior_structures 
prior.1<-list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0.002)))
prior.2<-list(R=list(V=2, fix=1), G=list(G1=list(V=1, nu=0)))

  
  if (lhs == 'log') {
    mcmc_formula <-
      as.formula(paste(
        "cbind(cenMin_log, cenMax_log) ~ ",
        paste0(fixed_list , collapse = "+")
      ))
  }
  else {
    mcmc_formula <-
      as.formula(paste(
        "cbind(cenMin, cenMax) ~ ",
        paste0(fixed_list , collapse = "+")
      ))
  }
  
  mcmc_results <-
    MCMCglmm(
      mcmc_formula,
      random = ~ Location,
      data =  data,
      family = "cengaussian", 
      verbose = FALSE, prior = prior.1, singular.ok = TRUE,
      nitt = 60000, thin = 13, burnin = 10000
    )
    return((mcmc_results))
}
```



##### function that returns bayesian plots
```{r}
# Do some predictive checks 
library(bayesplot)
color_scheme_set("blue")
bayes_plots <- function(fit,coc,df) {
#fit <- TSSModel

#coc = 'Total Suspended Solids - Water - Total'

#df <- (subset(s8data.wPredictors, parameter == coc)) %>%
 # add_surv()
yrep_c <- predict(fit, newdata=df, 
         type="response", interval="confidence", level=0.9, it=NULL, 
         posterior="all", verbose=FALSE, approx="numerical")
yrep_p <- predict(fit, newdata=df, 
         type="response", interval="prediction", level=0.9, it=NULL, 
         posterior="all", verbose=FALSE, approx="numerical")

#show uncertainty intervals under esimated posterior density curves 
plot.1 <- mcmc_areas(fit$Sol,prob = 0.80, pprob_outer = 0.95,point_est="mean")+ggplot2::labs(title = coc, subtitle   = "Posterior distributions with medians and 80% intervals")

#generate scatter plot of predictions 

colnames(yrep_p) <-  c("fit.p", "lwr.p", "upr.p")
scatterdata <- cbind(df, yrep_c, yrep_p)

#generate scatter plot of predictions 
plot.2 <- ggplot(scatterdata) + 
  geom_ribbon(aes(ymin = lwr.p, ymax = upr.p, x = fit),fill="grey", alpha = 0.5) + 
  geom_ribbon(aes(ymin = lwr, ymax = upr, x = fit), fill = "grey", alpha = 0.8) + 
  geom_line(aes(x=fit,y=fit),color="blue",linetype=5)+
  geom_point(aes(x = fit, y = log(concentration)), alpha = 0.5)+
  ggplot2::labs(x="yrep",y="fit",title = coc, subtitle   = "Scatter plot of observed data vs simulated",caption="dark shade: confidence intervals \n light shade: prediction intervals")


#simulate with 100 draws  
ysim <- (simulate(fit,nsim = 100))


#overlay of predictions 
plot.3<- ppc_dens_overlay(log(df$concentration),t(ysim))+ggplot2::labs(x="log concentration, μg/L ",title = coc, subtitle   = "Observed (y) vs. simulated draws (yrep)")


return(list(plot.1,plot.2,plot.3))
}
```

```{r}
#function for other diagnostic plots 
diagnostic_plots <- function(chains,coc) {
  plotTrace(chains,axes=TRUE,same.limits=TRUE)
  plotDens(chains,main=paste('Posterior Distributions \n',coc),probs=c(0.050,0.950),same.limits=FALSE)}
```


## Run model 

For each chunk below, we run the model and output diagnostic and prediction plots. 

## Zinc   
```{r fig.height=7}
# 
coc <- params[1]
ZnModel <- mcmc_calc(coc,c('impervious'),'log')
mod <- ZnModel
summary(mod)
df <- (subset(s8data.wPredictors, parameter == coc)) %>%
  add_surv()
bayes_plots(mod,coc,df)


```

## Copper    

```{r fig.height=7}
coc = 'Copper - Water - Total'
CuModel <- mcmc_calc(coc,c(
'rev_logTraffic','impervious'),'log')
mod <- CuModel
summary(mod$Sol)
summary(mod)
df <- (subset(s8data.wPredictors, parameter == coc)) %>%
  add_surv()
bayes_plots(mod,coc,df)

```



## Nitrite-Nitrate

```{r}
coc = 'Nitrite-Nitrate - Water - Dissolved'
NN_model <- mcmc_calc(coc,c(
'LU_ratio'),'log')
mod <- NN_model
summary(mod$Sol)
summary(mod)
df <- (subset(s8data.wPredictors, parameter == coc)) %>%
  add_surv()
bayes_plots(mod,coc,df)

```

## Lead   

```{r fig.height=7}
coc <- params[4]
PbModel <- mcmc_calc(params[4],c('impervious'),'log')

mod <- PbModel
summary(mod$Sol)
summary(mod)

df <- (subset(s8data.wPredictors, parameter == coc)) %>%
  add_surv()
bayes_plots(mod,coc,df)


```
## Cadium   

```{r fig.height=7}
coc <- 'Cadmium - Water - Total'
CdModel <- mcmc_calc('Cadmium - Water - Total',c('impervious','logPopulation'),'nonlog')
mod <- CdModel
summary(mod$Sol)
summary(mod)

df <- (subset(s8data.wPredictors, parameter == coc)) %>%
  add_surv()
bayes_plots(mod,coc,df)

```

## Total Phosphorus  

```{r fig.height=7}
coc = 'Total Phosphorus - Water - Total'
TPModel <- mcmc_calc('Total Phosphorus - Water - Total',c('rev_logTraffic'),'log')
mod <- TPModel
summary(mod$Sol)
summary(mod)

df <- (subset(s8data.wPredictors, parameter == coc)) %>%
  add_surv()
bayes_plots(mod,coc,df)
```

## Total Kjeldahl Nitrogen  

```{r fig.height=7}
coc = 'Total Kjeldahl Nitrogen - Water - Total'
TKNModel<- mcmc_calc('Total Kjeldahl Nitrogen - Water - Total','rev_logTraffic','log') 
mod <- TKNModel
df <- (subset(s8data.wPredictors, parameter == coc)) %>%
  add_surv()
bayes_plots(mod,coc,df)
```
## TSS  

```{r}
coc = 'Total Suspended Solids - Water - Total'
TSSModel <- mcmc_calc('Total Suspended Solids - Water - Total','rev_logTraffic','log')
df <- (subset(s8data.wPredictors, parameter == coc)) %>%
  add_surv()
bayes_plots(TSSModel,coc,df)


```
'Total PAH - Water - Total',
```{r}
coc = 'Total PAH - Water - Total'
PAHModel<- mcmc_calc('Total PAH - Water - Total','LU_ratio','log') 
mod <- PAHModel
df <- (subset(s8data.wPredictors, parameter == coc)) %>%
  add_surv()
bayes_plots(mod,coc,df)
```

'CPAH - Water - Total'
```{r}
coc = 'CPAH - Water - Total'
CPAHModel<- mcmc_calc('CPAH - Water - Total',c('logPopulation','rev_logTraffic'),'log') 
mod <- CPAHModel
df <- (subset(s8data.wPredictors, parameter == coc)) %>%
  add_surv()
bayes_plots(mod,coc,df)
```

'HPAH - Water - Total' 
```{r}
coc = 'HPAH - Water - Total'
HPAHModel<- mcmc_calc('HPAH - Water - Total',c('LU_ratio'),'log') 
mod <- HPAHModel
df <- (subset(s8data.wPredictors, parameter == coc)) %>%
  add_surv()
bayes_plots(mod,coc,df)
```


# Summary  

Summarize posterior results for use in heatmap. 

```{r}
#summarize 
metals <- list()
metals[['Total Copper']] <- (CuModel)
metals[['Total Zinc']] <- (ZnModel)
metals[['Total Cadmium']]<- (CdModel)
metals[['Total Lead']]<- (PbModel)

others <- list() 
others[['Total Phosphorus']] <- TPModel
others[['Total Kjeldahl Nitrogen']] <- TKNModel
others[['Total Suspended Sediment']] <-  TSSModel
#others['FC'] <- FCModel 





msummary(metals,title='Total Metals',statistic_vertical = TRUE,statistic = 'conf.int', conf_level = 0.95)
msummary(others,title='Nutrients and TSS',statistic_vertical = TRUE,statistic = 'conf.int', conf_level = 0.95)
```


Print out a messy list of results for the heatmap 
```{r}
sols <- list()
sols[['Copper']] <-summary(CuModel)$solutions  
sols[['Zinc']] <-summary(ZnModel)$solutions  
sols[['Cadmium']] <-summary(CdModel)$solutions  
sols[['Lead']] <-summary(PbModel)$solutions  
sols[['TP']] <-summary(TPModel)$solutions  
sols[['TKN']] <-summary(TKNModel)$solutions  
sols[['TSS']] <-summary(TSSModel)$solutions  

for (n in 1:length(sols)){
  print(kable(sols[[n]],row.names = TRUE, caption = paste(names(sols)[n]," - Summary of MCMC model")))
}
```







```
